{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1czVdIlqnImH"
   },
   "source": [
    "## Assignment 3 - Generative Adversarial Network Programming (Full points: 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1KD3ZgLs80vY"
   },
   "source": [
    "This assignment is more like a tutorial. \n",
    "\n",
    "### About Grading\n",
    "(10 points)\n",
    "Essentially, you need to go through all the coding details we provide to you, and experiment with it. We will grade you by checking the history to see if you have run the code. \n",
    "(60 points) You need to complete certain code segments. If you don't completely go through the tutorial, you might fail this part.\n",
    "(30 points)\n",
    "Finally, you should adjust the hyperparameters to achieve a reasonable result (a lower printed loss) in order to receive a high grade.\n",
    "\n",
    "### Content\n",
    "In this assignment (with tutorial), you're going to create your first generative adversarial network (GAN). Specifically, you need to build and train a GAN that can generate hand-written images of digits (0 to 9). You will be using PyTorch in this specialization, so if you're not familiar with this framework, you may find the [PyTorch documentation](https://pytorch.org/docs/stable/index.html) useful. The hints will also often include links to relevant documentation. \n",
    "\n",
    "### Warning\n",
    "If you encounter code errors (bugs), even in the tutorial, please attempt to resolve them independently, search for solutions using search engines such as Google, or seek advice from fellow classmates (plagiarism is not permitted). Failing to rectify bugs within the assignment or merely writing code without producing executable results will result in a significant deduction of points.\n",
    "\n",
    "### Objectives\n",
    "1.   Build the generator and discriminator components of a GAN from scratch.\n",
    "2.   Create generator and discriminator loss functions.\n",
    "3.   Train your GAN and visualize the generated images.\n",
    "\n",
    "\n",
    "### Key Concepts & Review\n",
    "\n",
    "##### MNIST Dataset\n",
    "The training images your discriminator will be using is from a dataset called MNIST. It contains 60,000 images of handwritten digits, from 0 to 9. (Google it if you want to see the details.)\n",
    "\n",
    "You may notice that the images are quite pixelated -- this is because they are all only 28 x 28! The small size of its images makes MNIST ideal for simple training. Additionally, these images are also in black-and-white so only one dimension, or \"color channel\").\n",
    "\n",
    "##### Tensor\n",
    "You will represent the data using [tensors](https://pytorch.org/docs/stable/tensors.html). Tensors are a generalization of matrices: for example, a stack of three matrices with the amounts of red, green, and blue at different locations in a 64 x 64 pixel image is a tensor with the shape 3 x 64 x 64.\n",
    "\n",
    "Tensors are easy to manipulate and supported by [PyTorch](https://pytorch.org/), the library you will be using. Feel free to explore them more, but you can imagine these as multi-dimensional matrices or vectors!\n",
    "\n",
    "##### Batches\n",
    "While you could train your model after generating one image, it is extremely inefficient and leads to less stable training. In GANs, and in deep learning in general, you will process multiple images per training step. These are called batches.\n",
    "\n",
    "This means that your generator will generate an entire batch of images and receive the discriminator's feedback on each before updating the model. The same goes for the discriminator, it will calculate its loss on the entire batch of generated images as well as on the reals before the model is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n",
      "GPU is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wU8DDM6l9rZb"
   },
   "source": [
    "# Tutorial (10 points)\n",
    "\n",
    "You will begin by importing some useful packages and the dataset you will use to build and train your GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfkorNJrnmNO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaken\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in a uniform grid.\n",
    "    '''\n",
    "    image_unflat = image_tensor.view(-1, *size).detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1A1M6kpnfxw"
   },
   "source": [
    "## Generator\n",
    "The first step is to build the generator component.\n",
    "\n",
    "You will start by creating a function to make a single layer/block for the generator's neural network. Each block should include a [linear transformation](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) to map to another shape, a [batch normalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html) for stabilization, and finally a non-linear activation function (you use a [ReLU here](https://pytorch.org/docs/master/generated/torch.nn.ReLU.html)) so the output can be transformed in complex ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZbqdw21hK5i"
   },
   "outputs": [],
   "source": [
    "def get_generator_block(input_dim, output_dim):\n",
    "    '''\n",
    "    Function for returning a block of the generator's neural network\n",
    "    given input and output dimensions.\n",
    "    Parameters:\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        output_dim: the dimension of the output vector, a scalar\n",
    "    Returns:\n",
    "        a generator neural network layer, with a linear transformation \n",
    "          followed by a batch normalization and then a relu activation\n",
    "    '''\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSggwl1J-XBt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Verify the generator block function\n",
    "def test_gen_block(in_features, out_features, num_test=1000):\n",
    "    block = get_generator_block(in_features, out_features)\n",
    "\n",
    "    # Check the three parts\n",
    "    assert len(block) == 3\n",
    "    assert type(block[0]) == nn.Linear\n",
    "    assert type(block[1]) == nn.BatchNorm1d\n",
    "    assert type(block[2]) == nn.ReLU\n",
    "    \n",
    "    # Check the output shape\n",
    "    test_input = torch.randn(num_test, in_features)\n",
    "    test_output = block(test_input)\n",
    "    assert tuple(test_output.shape) == (num_test, out_features)\n",
    "    assert test_output.std() > 0.55\n",
    "    assert test_output.std() < 0.65\n",
    "\n",
    "test_gen_block(25, 12)\n",
    "test_gen_block(15, 28)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nEihsdhOrU0m"
   },
   "source": [
    "Now you can build the generator class. It will take 3 values:\n",
    "\n",
    "*   The noise vector dimension\n",
    "*   The image dimension\n",
    "*   The initial hidden dimension\n",
    "\n",
    "Using these values, the generator will build a neural network with 5 layers/blocks. Beginning with the noise vector, the generator will apply non-linear transformations via the block function until the tensor is mapped to the size of the image to be outputted (the same size as the real images from MNIST). You will need to fill in the code for final layer since it is different than the others. The final layer does not need a normalization or activation function, but does need to be scaled with a [sigmoid function](https://pytorch.org/docs/master/generated/torch.nn.Sigmoid.html). \n",
    "\n",
    "Finally, you are given a forward pass function that takes in a noise vector and generates an image of the output dimension using your neural network.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"green\">\n",
    "<b>Optional hints for <code><font size=\"4\">Generator</font></code></b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "1. The output size of the final linear transformation should be im_dim, but remember you need to scale the outputs between 0 and 1 using the sigmoid function.\n",
    "2. [nn.Linear](https://pytorch.org/docs/master/generated/torch.nn.Linear.html) and [nn.Sigmoid](https://pytorch.org/docs/master/generated/torch.nn.Sigmoid.html) will be useful here. \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvO7h0LYnEJZ"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Generator Class\n",
    "    Values:\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        im_dim: the dimension of the images, fitted for the dataset used, a scalar\n",
    "          (MNIST images are 28 x 28 = 784 so that is your default)\n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):\n",
    "        super(Generator, self).__init__()\n",
    "        # Build the neural network\n",
    "        self.gen = nn.Sequential(\n",
    "            get_generator_block(z_dim, hidden_dim),\n",
    "            get_generator_block(hidden_dim, hidden_dim * 2),\n",
    "            get_generator_block(hidden_dim * 2, hidden_dim * 4),\n",
    "            get_generator_block(hidden_dim * 4, hidden_dim * 8),\n",
    "            \n",
    "            nn.Linear(hidden_dim * 8, im_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        '''\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor, \n",
    "        returns generated images.\n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
    "        '''\n",
    "        return self.gen(noise)\n",
    "    \n",
    "    def get_gen(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            the sequential model\n",
    "        '''\n",
    "        return self.gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0UW5DetBIY8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Verify the generator class\n",
    "def test_generator(z_dim, im_dim, hidden_dim, num_test=10000):\n",
    "    gen = Generator(z_dim, im_dim, hidden_dim).get_gen()\n",
    "    \n",
    "    # Check there are six modules in the sequential part\n",
    "    assert len(gen) == 6\n",
    "    test_input = torch.randn(num_test, z_dim)\n",
    "    test_output = gen(test_input)\n",
    "\n",
    "    # Check that the output shape is correct\n",
    "    assert tuple(test_output.shape) == (num_test, im_dim)\n",
    "    assert test_output.max() < 1, \"Make sure to use a sigmoid\"\n",
    "    assert test_output.min() > 0, \"Make sure to use a sigmoid\"\n",
    "    assert test_output.std() > 0.05, \"Don't use batchnorm here\"\n",
    "    assert test_output.std() < 0.15, \"Don't use batchnorm here\"\n",
    "\n",
    "test_generator(5, 10, 20)\n",
    "test_generator(20, 8, 24)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FLX69EaqRjn"
   },
   "source": [
    "## Noise\n",
    "To be able to use your generator, you will need to be able to create noise vectors. The noise vector z has the important role of making sure the images generated from the same class don't all look the same -- think of it as a random seed. You will generate it randomly using PyTorch by sampling random numbers from the normal distribution. Since multiple images will be processed per pass, you will generate all the noise vectors at once.\n",
    "\n",
    "Note that whenever you create a new tensor using torch.ones, torch.zeros, or torch.randn, you either need to create it on the target device, e.g. `torch.ones(3, 3, device=device)`, or move it onto the target device using `torch.ones(3, 3).to(device)`. You do not need to do this if you're creating a tensor by manipulating another tensor or by using a variation that defaults the device to the input, such as `torch.ones_like`. In general, use `torch.ones_like` and `torch.zeros_like` instead of `torch.ones` or `torch.zeros` where possible.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"green\">\n",
    "<b>Optional hint for <code><font size=\"4\">get_noise</font></code></b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "1. \n",
    "You will probably find [torch.randn](https://pytorch.org/docs/master/generated/torch.randn.html) useful here.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8COwJ9PkqUyd"
   },
   "outputs": [],
   "source": [
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    '''\n",
    "    Function for creating noise vectors: Given the dimensions (n_samples, z_dim),\n",
    "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
    "    Parameters:\n",
    "        n_samples: the number of samples to generate, a scalar\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        device: the device type\n",
    "    '''\n",
    "    # NOTE: To use this on GPU with device='cuda', make sure to pass the device \n",
    "    # argument to the function you use to generate the noise.\n",
    "    return torch.randn(n_samples, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PgWdQK-7P3qN",
    "outputId": "f4040a6f-1bfb-4af9-f04f-a7ede3ac16f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success on gpu!\n"
     ]
    }
   ],
   "source": [
    "# Verify the noise vector function\n",
    "def test_get_noise(n_samples, z_dim, device='cpu'):\n",
    "    noise = get_noise(n_samples, z_dim, device)\n",
    "    \n",
    "    # Make sure a normal distribution was used\n",
    "    assert tuple(noise.shape) == (n_samples, z_dim)\n",
    "    assert torch.abs(noise.std() - torch.tensor(1.0)) < 0.01\n",
    "    assert str(noise.device).startswith(device)\n",
    "\n",
    "test_get_noise(1000, 100, 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    test_get_noise(1000, 32, 'cuda')\n",
    "    print(\"Success on gpu!\")\n",
    "else:\n",
    "    print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9fScH98nkYH"
   },
   "source": [
    "## Discriminator\n",
    "The second component that you need to construct is the discriminator. As with the generator component, you will start by creating a function that builds a neural network block for the discriminator.\n",
    "\n",
    "*Note: You use leaky ReLUs to prevent the \"dying ReLU\" problem, which refers to the phenomenon where the parameters stop changing due to consistently negative values passed to a ReLU, which result in a zero gradient. You will learn more about this in the following lectures!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYi8YFcseYFK"
   },
   "outputs": [],
   "source": [
    "def get_discriminator_block(input_dim, output_dim):\n",
    "    '''\n",
    "    Discriminator Block\n",
    "    Function for returning a neural network of the discriminator given input and output dimensions.\n",
    "    Parameters:\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        output_dim: the dimension of the output vector, a scalar\n",
    "    Returns:\n",
    "        a discriminator neural network layer, with a linear transformation \n",
    "          followed by an nn.LeakyReLU activation with negative slope of 0.2 \n",
    "          (https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html)\n",
    "    '''\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.LeakyReLU(0.2, inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2r7Uh_GnCnAb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Verify the discriminator block function\n",
    "def test_disc_block(in_features, out_features, num_test=10000):\n",
    "    block = get_discriminator_block(in_features, out_features)\n",
    "\n",
    "    # Check there are two parts\n",
    "    assert len(block) == 2\n",
    "    test_input = torch.randn(num_test, in_features)\n",
    "    test_output = block(test_input)\n",
    "\n",
    "    # Check that the shape is right\n",
    "    assert tuple(test_output.shape) == (num_test, out_features)\n",
    "    \n",
    "    # Check that the LeakyReLU slope is about 0.2\n",
    "    assert -test_output.min() / test_output.max() > 0.1\n",
    "    assert -test_output.min() / test_output.max() < 0.3\n",
    "    assert test_output.std() > 0.3\n",
    "    assert test_output.std() < 0.5\n",
    "\n",
    "test_disc_block(25, 12)\n",
    "test_disc_block(15, 28)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tco9ffKnaNS"
   },
   "source": [
    "Now you can use these blocks to make a discriminator! The discriminator class holds 2 values:\n",
    "\n",
    "*   The image dimension\n",
    "*   The hidden dimension\n",
    "\n",
    "The discriminator will build a neural network with 4 layers. It will start with the image tensor and transform it until it returns a single number (1-dimension tensor) output. This output classifies whether an image is fake or real. Note that you do not need a sigmoid after the output layer since it is included in the loss function. Finally, to use your discrimator's neural network you are given a forward pass function that takes in an image tensor to be classified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aA4AxGnmpuPq"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    '''\n",
    "    Discriminator Class\n",
    "    Values:\n",
    "        im_dim: the dimension of the images, fitted for the dataset used, a scalar\n",
    "            (MNIST images are 28x28 = 784 so that is your default)\n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, im_dim=784, hidden_dim=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            get_discriminator_block(im_dim, hidden_dim * 4),\n",
    "            get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n",
    "            get_discriminator_block(hidden_dim * 2, hidden_dim),\n",
    "            # Hint: You want to transform the final output into a single value,\n",
    "            #       so add one more linear map.\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        '''\n",
    "        Function for completing a forward pass of the discriminator: Given an image tensor, \n",
    "        returns a 1-dimension tensor representing fake/real.\n",
    "        Parameters:\n",
    "            image: a flattened image tensor with dimension (im_dim)\n",
    "        '''\n",
    "        return self.disc(image)\n",
    "    \n",
    "    # Needed for grading\n",
    "    def get_disc(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            the sequential model\n",
    "        '''\n",
    "        return self.disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Verify the discriminator class\n",
    "def test_discriminator(z_dim, hidden_dim, num_test=100):\n",
    "    \n",
    "    disc = Discriminator(z_dim, hidden_dim).get_disc()\n",
    "\n",
    "    # Check there are three parts\n",
    "    assert len(disc) == 4\n",
    "\n",
    "    # Check the linear layer is correct\n",
    "    test_input = torch.randn(num_test, z_dim)\n",
    "    test_output = disc(test_input)\n",
    "    assert tuple(test_output.shape) == (num_test, 1)\n",
    "    \n",
    "    # Make sure there's no sigmoid\n",
    "    assert test_input.max() > 1\n",
    "    assert test_input.min() < -1\n",
    "\n",
    "test_discriminator(5, 10)\n",
    "test_discriminator(20, 8)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qRk_8azSq3tF"
   },
   "source": [
    "# (60 points) Complete the missing code\n",
    "# (30 points) Turning hyperparameters to get a great performance (with lower printed loss).\n",
    "\n",
    "Now you can put it all together!\n",
    "First, you will set your parameters:\n",
    "  *   criterion: the loss function\n",
    "  *   n_epochs: the number of times you iterate through the entire dataset when training\n",
    "  *   z_dim: the dimension of the noise vector\n",
    "  *   display_step: how often to display/visualize the images\n",
    "  *   batch_size: the number of images per forward/backward pass\n",
    "  *   lr: the learning rate\n",
    "  *   device: the device type, here using a GPU (which runs CUDA), not CPU\n",
    "\n",
    "Next, you will load the MNIST dataset as tensors using a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your parameters\n",
    "\n",
    "# Base: z-dim = 64, batch = 128, lr = 0.00001 on both\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 100\n",
    "z_dim = 32\n",
    "batch_size = 64\n",
    "gen_lr = 0.00002\n",
    "disc_lr = 0.00001\n",
    "\n",
    "display_step = 938\n",
    "disc_fake_loss_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356,
     "referenced_widgets": [
      "791aedb58fb54771a08f96b47b26d7ca",
      "867756ae36e148bebdfae863cd8bea78",
      "6d5079e5fc004921935be00b8ef0e73c",
      "b678b1e6ac9445e1bba0dfba02ff6838",
      "ff768e3eb4494343bbf05ac9c8536f5c",
      "efd48396f02d470eb8f94e83102a97dc",
      "1e2b39fe404341a4b866a54e4196b447",
      "c436056304df43d888975a16877d0e2b",
      "7f785f474591493ea48c41fc3c8fb6a4",
      "f4acb82569474ed588e72657b7d61f13",
      "9b08f4d7f68a48698a30af50d978be18",
      "94eeb6dd98a3468c814fca2b17cc906d",
      "ac66fb3a3e8d4aed9d968e84c897fda4",
      "5f8684679588469f85d86b048889387e",
      "de3e18d80f1f4456842b66443b4fd9b7",
      "428037c978c04996aa56db81ee78ce2d",
      "f872d3f827994ea8906aa099a6e8700c",
      "a36ea3adaed746e8a451a80ed8aead03",
      "5d89702ec9374bf3aac8578f054a82f5",
      "31dff524ad6b460cae8d9a3551f1e760",
      "a86e0520284b4aa19275c34285c7fb5f",
      "759c15230b394b658c44dc1e07beb3aa",
      "523435d58a2e43ecb3f7f8000596ca00",
      "9faf93e4798849d0bb2bc7e139727a5c",
      "73d88a452b9e42b4a0b8b65a12eb1434",
      "4acd094e38964d92853ec2c1be206601",
      "fe3d17d3edd747958139d93df703115e",
      "954c2a0b14674a9dbc6c12e6bef4ae26",
      "c1c7ab8fb8684b428e1a126535aaaff2",
      "3c1313fa41c64640b481590c79771343",
      "c1c31dce322e449bbecb8b82b87145ab",
      "a31698d216f44a2898c42baa759b6bbc"
     ]
    },
    "colab_type": "code",
    "id": "IFLQ039u-qdu",
    "outputId": "7213a396-8f84-4fe0-ad5e-9d5748a5750d"
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset as tensors\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "device = 'cuda' # or 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24Var22i_Ccs"
   },
   "source": [
    "Now, you can initialize your generator, discriminator, and optimizers. Note that each optimizer only takes the parameters of one particular model, since we want each optimizer to optimize only one of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDFRZ8tg_Y57",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=gen_lr)\n",
    "disc = Discriminator().to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=disc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7iCTg3w4_Zw6"
   },
   "source": [
    "Before you train your GAN, you will need to create functions to calculate the discriminator's loss and the generator's loss. This is how the discriminator and generator will know how they are doing and improve themselves. Since the generator is needed when calculating the discriminator's loss, you will need to call .detach() on the generator result to ensure that only the discriminator is updated!\n",
    "\n",
    "Remember that you have already defined a loss function earlier (`criterion`) and you are encouraged to use `torch.ones_like` and `torch.zeros_like` instead of `torch.ones` or `torch.zeros` to set the labels. If you use `torch.ones` or `torch.zeros`, you'll need to pass `device=device` to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYzBtiYyz8IJ"
   },
   "outputs": [],
   "source": [
    "def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device, fake_loss_ratio=0.5):\n",
    "    '''\n",
    "    Return the loss of the discriminator given inputs.\n",
    "    Parameters:\n",
    "        gen: the generator model, which returns an image given z-dimensional noise\n",
    "        disc: the discriminator model, which returns a single-dimensional prediction of real/fake\n",
    "        criterion: the loss function, which should be used to compare \n",
    "               the discriminator's predictions to the ground truth reality of the images \n",
    "               (e.g. fake = 0, real = 1)\n",
    "        real: a batch of real images\n",
    "        num_images: the number of images the generator should produce, \n",
    "                which is also the length of the real images\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        device: the device type\n",
    "    Returns:\n",
    "        disc_loss: a torch scalar loss value for the current batch\n",
    "    '''\n",
    "    #     These are the steps you will need to complete:\n",
    "    #       1) Create noise vectors and generate a batch (num_images) of fake images. \n",
    "    #            Make sure to pass the device argument to the noise.\n",
    "    #       2) Get the discriminator's prediction of the fake image \n",
    "    #            and calculate the loss. Don't forget to detach the generator!\n",
    "    #            (Remember the loss function you set earlier -- criterion. You need a \n",
    "    #            'ground truth' tensor in order to calculate the loss. \n",
    "    #            For example, a ground truth tensor for a fake image is all zeros.)\n",
    "    #       3) Get the discriminator's prediction of the real image and calculate the loss.\n",
    "    #       4) Calculate the discriminator's loss by averaging the real and fake loss\n",
    "    #            and set it to disc_loss.\n",
    "    #     Note: Please do not use concatenation in your solution. The tests are being updated to \n",
    "    #           support this, but for now, average the two losses as described in step (4).\n",
    "    #     *Important*: You should NOT write your own loss function here - use criterion(pred, true)!\n",
    "    #### START CODE HERE ####\n",
    "    noise = get_noise(n_samples=num_images, z_dim=z_dim, device=device)\n",
    "    fake_image_gen = gen(noise).detach()\n",
    "    fake_image_pred = disc(fake_image_gen)\n",
    "    fake_image_loss = criterion(fake_image_pred, torch.zeros_like(fake_image_pred))\n",
    "    real_image_pred = disc(real)\n",
    "    real_image_loss = criterion(real_image_pred, torch.ones_like(real_image_pred))\n",
    "    disc_loss = (fake_image_loss * fake_loss_ratio) + (real_image_loss * (1 - fake_loss_ratio))\n",
    "    #### END CODE HERE ####\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zV_8i6y30nTE"
   },
   "outputs": [],
   "source": [
    "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
    "    '''\n",
    "    Return the loss of the generator given inputs.\n",
    "    Parameters:\n",
    "        gen: the generator model, which returns an image given z-dimensional noise\n",
    "        disc: the discriminator model, which returns a single-dimensional prediction of real/fake\n",
    "        criterion: the loss function, which should be used to compare \n",
    "               the discriminator's predictions to the ground truth reality of the images \n",
    "               (e.g. fake = 0, real = 1)\n",
    "        num_images: the number of images the generator should produce, \n",
    "                which is also the length of the real images\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        device: the device type\n",
    "    Returns:\n",
    "        gen_loss: a torch scalar loss value for the current batch\n",
    "    '''\n",
    "    #     These are the steps you will need to complete:\n",
    "    #       1) Create noise vectors and generate a batch of fake images. \n",
    "    #           Remember to pass the device argument to the get_noise function.\n",
    "    #       2) Get the discriminator's prediction of the fake image.\n",
    "    #       3) Calculate the generator's loss. Remember the generator wants\n",
    "    #          the discriminator to think that its fake images are real\n",
    "    #     *Important*: You should NOT write your own loss function here - use criterion(pred, true)!\n",
    "\n",
    "    #### START CODE HERE ####\n",
    "    noise = get_noise(n_samples=num_images, z_dim=z_dim, device=device)\n",
    "    fake_image_gen = gen(noise)\n",
    "    fake_image_pred = disc(fake_image_gen)\n",
    "    gen_loss = criterion(fake_image_pred, torch.ones_like(fake_image_pred))\n",
    "    #### END CODE HERE ####\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vua5_hRMRb60"
   },
   "source": [
    "Finally, you can put everything together! For each epoch, you will process the entire dataset in batches. For every batch, you will need to update the discriminator and generator using their loss. Note that you may see a loss to be greater than 1, this is okay since binary cross entropy loss can be any positive number for a sufficiently confident wrong guess. \n",
    "\n",
    "It’s also often the case that the discriminator will outperform the generator, especially at the start, because its job is easier. It's important that neither one gets too good (that is, near-perfect accuracy), which would cause the entire model to stop learning. Balancing the two models is actually remarkably hard to do in a standard GAN.\n",
    "\n",
    "In addition, be warned that this runs very slowly on a CPU. One way to run this more quickly is to use Google Colab: \n",
    "\n",
    "1.   Download the .ipynb\n",
    "2.   Upload it to Google Drive and open it with Google Colab\n",
    "3.   Make the runtime type GPU (under “Runtime” -> “Change runtime type” -> Select “GPU” from the dropdown)\n",
    "4.   Replace `device = \"cpu\"` with `device = \"cuda\"`\n",
    "5.   Make sure your `get_noise` function uses the right device -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "| Parameter Changes | Epoch 10 | Epoch 25 | Epoch 50 | Epoch 75 | Epoch 99 |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| Base | 3.57, 0.065 | 4.15, 0.071 | 2.99, 0.178 | 2.52, 0.24 | 1.85, 0.336 |\n",
    "| Z-dim = 128 | 3.33, 0.073 | 4.28, 0.074 | 2.99, 0.197 | 2.37, 0.267 | 2.08, 0.306 |\n",
    "| Z-dim = 32 | 2.90, 0.112 | 3.85, 0.077 | 3.07, 0.169 | 2.37, 0.250 | 2.04, 0.296 |\n",
    "| batch size = 64 | 3.67, 0.085 | 2.98, 0.184 | 1.88, 0.333 | 1.42, 0.444 | 1.24, 0.496 |\n",
    "| batch 64, z 32 | * | * | * | * | 1.18, 0.515 |\n",
    "| Z-dim = 16 | * | * | * | * | 2.43, 0.250 |\n",
    "| batch 64, z 16 | * | * | * | * | 1.62, 0.373 |\n",
    "| batch 64, z 24 | * | * | * | * | 1.93, 0.345 |\n",
    "| batch 64, z 32, gen-lr = 0.0001 | * | * | * | * | 0.79, 0.667 (stagnates at epoch 1, likely local minima) |\n",
    "| batch 64, z 32, gen-lr = 0.00005 | * | * | * | * | 0.977, 0.552 |\n",
    "| batch 64, z 32, gen-lr = 0.00003 | * | * | * | 0.894, 0.614 (best result) | * |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UXptQZcwrBrq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 37.55it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 33.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 938: Generator loss: 0.8556798150671571, discriminator loss: 0.6058768940759879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 38.56it/s]\n",
      "  1%|          | 8/938 [00:00<00:28, 32.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, step 1876: Generator loss: 0.9683234822521345, discriminator loss: 0.5103999573920072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 38.73it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 33.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, step 2814: Generator loss: 1.1729404955530465, discriminator loss: 0.41778888904463884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 38.98it/s]\n",
      "  1%|          | 8/938 [00:00<00:27, 33.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, step 3752: Generator loss: 1.6685404307298317, discriminator loss: 0.2632069800581252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 39.21it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 33.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, step 4690: Generator loss: 1.7727488178942497, discriminator loss: 0.28745855546709337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 38.19it/s]\n",
      "  0%|          | 3/938 [00:00<00:39, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, step 5628: Generator loss: 1.836919936035742, discriminator loss: 0.28865427504788077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 38.30it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 34.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, step 6566: Generator loss: 1.8564138839493967, discriminator loss: 0.29385407413564485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 40.34it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 35.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, step 7504: Generator loss: 2.0247525524483057, discriminator loss: 0.271481543604626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 39.08it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 33.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, step 8442: Generator loss: 2.0856809110275467, discriminator loss: 0.2650676186500331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.59it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 37.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, step 9380: Generator loss: 2.2292908010706465, discriminator loss: 0.24935411383856607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.30it/s]\n",
      "  0%|          | 4/938 [00:00<00:28, 32.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, step 10318: Generator loss: 2.4248222811644022, discriminator loss: 0.2063085976312915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.01it/s]\n",
      "  1%|          | 8/938 [00:00<00:25, 36.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, step 11256: Generator loss: 2.15617134131348, discriminator loss: 0.2791437685314907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.97it/s]\n",
      "  1%|          | 8/938 [00:00<00:25, 36.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, step 12194: Generator loss: 2.2252466731996674, discriminator loss: 0.2454578055263453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.16it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 34.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, step 13132: Generator loss: 2.1011745239625874, discriminator loss: 0.29712927060277194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 39.61it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 35.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, step 14070: Generator loss: 2.1854342157398436, discriminator loss: 0.26906477343807333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.59it/s]\n",
      "  1%|          | 8/938 [00:00<00:25, 36.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, step 15008: Generator loss: 2.0644611427778865, discriminator loss: 0.3117547574073775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.33it/s]\n",
      "  1%|          | 8/938 [00:00<00:25, 36.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, step 15946: Generator loss: 2.0257504653574814, discriminator loss: 0.32879168195511055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:21<00:00, 42.67it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 38.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, step 16884: Generator loss: 2.028391625962532, discriminator loss: 0.3438115867057331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 42.27it/s]\n",
      "  0%|          | 4/938 [00:00<00:29, 31.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, step 17822: Generator loss: 1.9754163448744495, discriminator loss: 0.3129722804847811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.02it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 34.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, step 18760: Generator loss: 2.0716276233638533, discriminator loss: 0.3069301756428504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 40.83it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 35.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, step 19698: Generator loss: 1.9712607342042887, discriminator loss: 0.32052634109947503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 40.83it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 37.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, step 20636: Generator loss: 2.074803333800992, discriminator loss: 0.3074967636704958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.56it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 33.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, step 21574: Generator loss: 1.819621019653166, discriminator loss: 0.3898864861395057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.38it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 37.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, step 22512: Generator loss: 1.9509903932176944, discriminator loss: 0.3336041575111051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 42.24it/s]\n",
      "  1%|          | 8/938 [00:00<00:25, 37.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, step 23450: Generator loss: 1.9302829148164424, discriminator loss: 0.32826253882984635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.29it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 35.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, step 24388: Generator loss: 2.0225082670193486, discriminator loss: 0.3149193427614818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.25it/s]\n",
      "  0%|          | 4/938 [00:00<00:24, 37.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, step 25326: Generator loss: 1.9770604749478253, discriminator loss: 0.31530388490731825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 40.80it/s]\n",
      "  0%|          | 4/938 [00:00<00:25, 36.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, step 26264: Generator loss: 1.8446625802816883, discriminator loss: 0.37430694573787254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.06it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 35.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, step 27202: Generator loss: 1.7402458300214325, discriminator loss: 0.3794581765559181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 42.51it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 35.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, step 28140: Generator loss: 1.818432827112773, discriminator loss: 0.340257392239088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 42.09it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 34.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, step 29078: Generator loss: 1.717727830415085, discriminator loss: 0.3886986738805578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.23it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 34.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, step 30016: Generator loss: 1.6937857058002486, discriminator loss: 0.3910808570381168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:25<00:00, 37.02it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 34.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, step 30954: Generator loss: 1.614053639902998, discriminator loss: 0.39962901912137105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 39.45it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 37.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, step 31892: Generator loss: 1.7623627230302599, discriminator loss: 0.366106935306144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 37.68it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 35.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, step 32830: Generator loss: 1.4819634446203076, discriminator loss: 0.45048898232898277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.88it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 35.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, step 33768: Generator loss: 1.439756768217475, discriminator loss: 0.4477288637842447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.44it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 34.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, step 34706: Generator loss: 1.4195124237522136, discriminator loss: 0.4588998267327803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 40.49it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 33.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, step 35644: Generator loss: 1.2937149294912191, discriminator loss: 0.4892226893828113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.41it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 34.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, step 36582: Generator loss: 1.414233540548189, discriminator loss: 0.4409661012481273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.83it/s]\n",
      "  0%|          | 4/938 [00:00<00:25, 36.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, step 37520: Generator loss: 1.39775594338171, discriminator loss: 0.4643564051402406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 42.03it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 35.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, step 38458: Generator loss: 1.4537682679416284, discriminator loss: 0.424918062381272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 40.96it/s]\n",
      "  0%|          | 4/938 [00:00<00:28, 32.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, step 39396: Generator loss: 1.474490765315381, discriminator loss: 0.42156254881417093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 42.05it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 35.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, step 40334: Generator loss: 1.4051654326127785, discriminator loss: 0.4340818312916672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 42.27it/s]\n",
      "  1%|          | 8/938 [00:00<00:25, 36.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, step 41272: Generator loss: 1.385627077205351, discriminator loss: 0.4401609088216764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 37.64it/s]\n",
      "  1%|          | 7/938 [00:00<00:30, 30.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, step 42210: Generator loss: 1.4094987071907596, discriminator loss: 0.4558593016475244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 39.39it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 37.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, step 43148: Generator loss: 1.515227338525533, discriminator loss: 0.38818745261062226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.82it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 34.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, step 44086: Generator loss: 1.385191119047626, discriminator loss: 0.44357990146255183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 40.73it/s]\n",
      "  0%|          | 4/938 [00:00<00:25, 36.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, step 45024: Generator loss: 1.366526865501648, discriminator loss: 0.43505499953590687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.41it/s]\n",
      "  1%|          | 8/938 [00:00<00:25, 35.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, step 45962: Generator loss: 1.3489553794932019, discriminator loss: 0.45290945980276875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.60it/s]\n",
      "  1%|          | 8/938 [00:00<00:25, 35.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, step 46900: Generator loss: 1.351951274536311, discriminator loss: 0.4558064339321051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 40.66it/s]\n",
      "  0%|          | 4/938 [00:00<00:29, 31.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, step 47838: Generator loss: 1.352733982270207, discriminator loss: 0.45200074205139323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.29it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 37.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, step 48776: Generator loss: 1.2977903073530466, discriminator loss: 0.4617902391246646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 42.23it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 34.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, step 49714: Generator loss: 1.2737192919513574, discriminator loss: 0.46914900035492096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 42.13it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 34.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, step 50652: Generator loss: 1.2148731888484345, discriminator loss: 0.5122121648430054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.68it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 34.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, step 51590: Generator loss: 1.2711780896700269, discriminator loss: 0.4640126927956338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.62it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 34.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, step 52528: Generator loss: 1.3120431704307656, discriminator loss: 0.4462292927509939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 40.41it/s]\n",
      "  1%|          | 8/938 [00:00<00:25, 36.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, step 53466: Generator loss: 1.2761402332198137, discriminator loss: 0.472492307869356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.95it/s]\n",
      "  0%|          | 4/938 [00:00<00:25, 36.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, step 54404: Generator loss: 1.0753890443712397, discriminator loss: 0.5433988765295135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:25<00:00, 36.19it/s]\n",
      "  0%|          | 4/938 [00:00<00:56, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, step 55342: Generator loss: 1.1339798917902533, discriminator loss: 0.5069028247775299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:31<00:00, 29.54it/s]\n",
      "  0%|          | 2/938 [00:00<00:56, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, step 56280: Generator loss: 1.0947878635895527, discriminator loss: 0.5245058041518685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:26<00:00, 35.93it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 35.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, step 57218: Generator loss: 1.1617361272194742, discriminator loss: 0.49170436997657646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.17it/s]\n",
      "  0%|          | 4/938 [00:00<00:24, 37.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, step 58156: Generator loss: 1.1585989682786242, discriminator loss: 0.4948239572393863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 40.68it/s]\n",
      "  0%|          | 4/938 [00:00<00:25, 36.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, step 59094: Generator loss: 1.067975315839241, discriminator loss: 0.5359599040960202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.15it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 35.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, step 60032: Generator loss: 0.9432738619699657, discriminator loss: 0.5632707696161794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.16it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 34.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, step 60970: Generator loss: 1.0670986422089377, discriminator loss: 0.5202929318141832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 40.15it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 35.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, step 61908: Generator loss: 1.0710135695141256, discriminator loss: 0.524621414795105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 40.87it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 35.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, step 62846: Generator loss: 1.021700161161708, discriminator loss: 0.5326781976642379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.62it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 35.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, step 63784: Generator loss: 1.0885791286095365, discriminator loss: 0.5109325896448155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 38.03it/s]\n",
      "  0%|          | 4/938 [00:00<00:29, 31.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, step 64722: Generator loss: 0.9888637511969112, discriminator loss: 0.547747465529676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:25<00:00, 36.69it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 35.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, step 65660: Generator loss: 1.044378190152426, discriminator loss: 0.5260557765518421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 40.98it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 33.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, step 66598: Generator loss: 1.14886378225233, discriminator loss: 0.49531681664081556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 40.82it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 34.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, step 67536: Generator loss: 0.8595547786018237, discriminator loss: 0.6181109044343424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 40.37it/s]\n",
      "  0%|          | 4/938 [00:00<00:29, 32.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73, step 68474: Generator loss: 0.8044908865174245, discriminator loss: 0.6229721396398946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 40.96it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 35.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74, step 69412: Generator loss: 0.8705126038873623, discriminator loss: 0.6062481235275897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 40.73it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 34.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, step 70350: Generator loss: 0.8937133648502302, discriminator loss: 0.6142002318078263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.60it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 35.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, step 71288: Generator loss: 1.2090835606238484, discriminator loss: 0.490432049483379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.59it/s]\n",
      "  0%|          | 4/938 [00:00<00:28, 33.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, step 72226: Generator loss: 1.0650894554184964, discriminator loss: 0.5124816876421094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.43it/s]\n",
      "  1%|          | 8/938 [00:00<00:23, 39.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, step 73164: Generator loss: 1.119334591477155, discriminator loss: 0.5096745789686499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.49it/s]\n",
      "  1%|          | 5/938 [00:00<00:21, 43.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, step 74102: Generator loss: 1.0458249016357124, discriminator loss: 0.5355656339224975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 39.06it/s]\n",
      "  0%|          | 4/938 [00:00<00:26, 35.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, step 75040: Generator loss: 1.0073642955024626, discriminator loss: 0.5533376964869534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.43it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 37.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, step 75978: Generator loss: 0.8272530037456993, discriminator loss: 0.628497233268804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 37.71it/s]\n",
      "  1%|          | 5/938 [00:00<00:21, 43.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, step 76916: Generator loss: 0.8452798071573533, discriminator loss: 0.6193396645123516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.84it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 37.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, step 77854: Generator loss: 0.950405170604872, discriminator loss: 0.580507494620423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.16it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 38.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84, step 78792: Generator loss: 0.8546515491598463, discriminator loss: 0.6253818484193984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.68it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 38.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, step 79730: Generator loss: 0.9759542100083846, discriminator loss: 0.5782143459963142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.35it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 38.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, step 80668: Generator loss: 1.0330384868040268, discriminator loss: 0.5492609708166835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 40.93it/s]\n",
      "  1%|          | 8/938 [00:00<00:24, 37.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, step 81606: Generator loss: 1.0533252980536236, discriminator loss: 0.5244150274534464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 37.69it/s]\n",
      "  0%|          | 3/938 [00:00<00:32, 28.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88, step 82544: Generator loss: 1.0243427306731363, discriminator loss: 0.5602538496065232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.06it/s]\n",
      "  0%|          | 4/938 [00:00<00:27, 33.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, step 83482: Generator loss: 1.1417081383372671, discriminator loss: 0.4988468770406396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:23<00:00, 40.22it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 35.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, step 84420: Generator loss: 1.0110841301966826, discriminator loss: 0.5502967911996819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.95it/s]\n",
      "  1%|          | 8/938 [00:00<00:27, 33.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91, step 85358: Generator loss: 0.9863487798522022, discriminator loss: 0.5725881931369992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 40.97it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 34.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92, step 86296: Generator loss: 1.134200731447256, discriminator loss: 0.49012535171849386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:25<00:00, 37.19it/s]\n",
      "  0%|          | 3/938 [00:00<00:34, 26.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93, step 87234: Generator loss: 1.1187489016223802, discriminator loss: 0.5120564061504949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:27<00:00, 34.10it/s]\n",
      "  1%|          | 8/938 [00:00<00:26, 34.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94, step 88172: Generator loss: 1.1313755038196336, discriminator loss: 0.5114103543605887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:22<00:00, 41.80it/s]\n",
      "  0%|          | 4/938 [00:00<00:28, 32.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, step 89110: Generator loss: 0.9861167953339725, discriminator loss: 0.5528468752402989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 335/938 [00:09<00:17, 34.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jaken\\Desktop\\CS577\\CS577_Assignment3.ipynb Cell 31\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jaken/Desktop/CS577/CS577_Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m error \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jaken/Desktop/CS577/CS577_Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jaken/Desktop/CS577/CS577_Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jaken/Desktop/CS577/CS577_Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Dataloader returns the batches\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jaken/Desktop/CS577/CS577_Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m real, _ \u001b[39min\u001b[39;00m tqdm(dataloader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jaken/Desktop/CS577/CS577_Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         cur_batch_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(real)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jaken/Desktop/CS577/CS577_Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39m# Flatten the batch of real images from the dataset\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jaken\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jaken\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\jaken\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\jaken\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\jaken\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\jaken\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\jaken\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32mc:\\Users\\jaken\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:174\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    172\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[1;32m--> 174\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n\u001b[0;32m    175\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "gen_loss = False\n",
    "error = False\n",
    "for epoch in range(n_epochs):\n",
    "  \n",
    "    # Dataloader returns the batches\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "\n",
    "        # Flatten the batch of real images from the dataset\n",
    "        real = real.view(cur_batch_size, -1).to(device)\n",
    "\n",
    "        ### Update discriminator ###\n",
    "        # Zero out the gradients before backpropagation\n",
    "        disc_opt.zero_grad()\n",
    "\n",
    "        # Calculate discriminator loss\n",
    "        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device, disc_fake_loss_ratio)\n",
    "\n",
    "        # Update gradients\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "\n",
    "        # Update optimizer\n",
    "        disc_opt.step()\n",
    "\n",
    "        ### Update generator ###\n",
    "        #     Hint: This code will look a lot like the discriminator updates!\n",
    "        #     These are the steps you will need to complete:\n",
    "        #       1) Zero out the gradients.\n",
    "        #       2) Calculate the generator loss, assigning it to gen_loss.\n",
    "        #       3) Backprop through the generator: update the gradients and optimizer.\n",
    "        #### START CODE HERE ####\n",
    "        gen_opt.zero_grad()\n",
    "        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)\n",
    "        gen_loss.backward(retain_graph=True)\n",
    "        gen_opt.step()\n",
    "        #### END CODE HERE ####\n",
    "\n",
    "        # Keep track of the average discriminator loss\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        ### Visualization code ###\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            #show_tensor_images(fake)\n",
    "            #show_tensor_images(real)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1KD3ZgLs80vY",
    "Mvjjan17qHjq"
   ],
   "name": "C1W1_9: Your First GAN (Student).ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "GANSC1-1A"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1e2b39fe404341a4b866a54e4196b447": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31dff524ad6b460cae8d9a3551f1e760": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9faf93e4798849d0bb2bc7e139727a5c",
      "placeholder": "​",
      "style": "IPY_MODEL_523435d58a2e43ecb3f7f8000596ca00",
      "value": " 1654784/? [00:16&lt;00:00, 293528.49it/s]"
     }
    },
    "3c1313fa41c64640b481590c79771343": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "428037c978c04996aa56db81ee78ce2d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4acd094e38964d92853ec2c1be206601": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "523435d58a2e43ecb3f7f8000596ca00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d89702ec9374bf3aac8578f054a82f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_759c15230b394b658c44dc1e07beb3aa",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a86e0520284b4aa19275c34285c7fb5f",
      "value": 1
     }
    },
    "5f8684679588469f85d86b048889387e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d5079e5fc004921935be00b8ef0e73c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efd48396f02d470eb8f94e83102a97dc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff768e3eb4494343bbf05ac9c8536f5c",
      "value": 1
     }
    },
    "73d88a452b9e42b4a0b8b65a12eb1434": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe3d17d3edd747958139d93df703115e",
       "IPY_MODEL_954c2a0b14674a9dbc6c12e6bef4ae26"
      ],
      "layout": "IPY_MODEL_4acd094e38964d92853ec2c1be206601"
     }
    },
    "759c15230b394b658c44dc1e07beb3aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "791aedb58fb54771a08f96b47b26d7ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6d5079e5fc004921935be00b8ef0e73c",
       "IPY_MODEL_b678b1e6ac9445e1bba0dfba02ff6838"
      ],
      "layout": "IPY_MODEL_867756ae36e148bebdfae863cd8bea78"
     }
    },
    "7f785f474591493ea48c41fc3c8fb6a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b08f4d7f68a48698a30af50d978be18",
       "IPY_MODEL_94eeb6dd98a3468c814fca2b17cc906d"
      ],
      "layout": "IPY_MODEL_f4acb82569474ed588e72657b7d61f13"
     }
    },
    "867756ae36e148bebdfae863cd8bea78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94eeb6dd98a3468c814fca2b17cc906d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_428037c978c04996aa56db81ee78ce2d",
      "placeholder": "​",
      "style": "IPY_MODEL_de3e18d80f1f4456842b66443b4fd9b7",
      "value": " 32768/? [00:17&lt;00:00, 86439.38it/s]"
     }
    },
    "954c2a0b14674a9dbc6c12e6bef4ae26": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a31698d216f44a2898c42baa759b6bbc",
      "placeholder": "​",
      "style": "IPY_MODEL_c1c31dce322e449bbecb8b82b87145ab",
      "value": " 0/4542 [00:00&lt;?, ?it/s]"
     }
    },
    "9b08f4d7f68a48698a30af50d978be18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f8684679588469f85d86b048889387e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ac66fb3a3e8d4aed9d968e84c897fda4",
      "value": 1
     }
    },
    "9faf93e4798849d0bb2bc7e139727a5c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a31698d216f44a2898c42baa759b6bbc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a36ea3adaed746e8a451a80ed8aead03": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a86e0520284b4aa19275c34285c7fb5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ac66fb3a3e8d4aed9d968e84c897fda4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b678b1e6ac9445e1bba0dfba02ff6838": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c436056304df43d888975a16877d0e2b",
      "placeholder": "​",
      "style": "IPY_MODEL_1e2b39fe404341a4b866a54e4196b447",
      "value": " 9920512/? [00:20&lt;00:00, 1676415.51it/s]"
     }
    },
    "c1c31dce322e449bbecb8b82b87145ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1c7ab8fb8684b428e1a126535aaaff2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c436056304df43d888975a16877d0e2b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de3e18d80f1f4456842b66443b4fd9b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efd48396f02d470eb8f94e83102a97dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4acb82569474ed588e72657b7d61f13": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f872d3f827994ea8906aa099a6e8700c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5d89702ec9374bf3aac8578f054a82f5",
       "IPY_MODEL_31dff524ad6b460cae8d9a3551f1e760"
      ],
      "layout": "IPY_MODEL_a36ea3adaed746e8a451a80ed8aead03"
     }
    },
    "fe3d17d3edd747958139d93df703115e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c1313fa41c64640b481590c79771343",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c1c7ab8fb8684b428e1a126535aaaff2",
      "value": 0
     }
    },
    "ff768e3eb4494343bbf05ac9c8536f5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
